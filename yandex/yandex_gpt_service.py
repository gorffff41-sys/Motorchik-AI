#!/usr/bin/env python3
"""
–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å YandexGPT
"""

import os
import sys
import time
import json
import logging
import torch
from typing import Dict, List, Optional, Any
from datetime import datetime

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –∫–æ—Ä–Ω–µ–≤–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

logger = logging.getLogger("yandex_gpt_service")

class YandexGPTService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å YandexGPT"""
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–∞"""
        self.model = None
        self.tokenizer = None
        self.device = None
        self.available = False
        self.model_name = "yandex/YandexGPT-5-Lite-8B-instruct"
        
        logger.info("ü§ñ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è YandexGPT —Å–µ—Ä–≤–∏—Å–∞...")
        self._init_model()
    
    def _init_model(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ YandexGPT"""
        try:
            from transformers import AutoModelForCausalLM, AutoTokenizer
            
            logger.info("üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ YandexGPT...")
            self.tokenizer = AutoTokenizer.from_pretrained(
                self.model_name,
                trust_remote_code=True,
                use_fast=False
            )
            logger.info("‚úÖ –¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω")
            
            logger.info("üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ YandexGPT...")
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å CUDA
            self.device = "cuda" if torch.cuda.is_available() else "cpu"
            logger.info(f"üîß –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device}")
            
            self.model = AutoModelForCausalLM.from_pretrained(
                self.model_name,
                trust_remote_code=True,
                device_map="auto" if self.device == "cuda" else None,
                torch_dtype="auto" if self.device == "cuda" else torch.float32,
            )
            
            if self.device == "cpu":
                self.model = self.model.to(self.device)
            
            logger.info("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            self.available = True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ YandexGPT: {e}")
            self.available = False
    
    def generate_response(self, query: str, user_id: str = "default", context: Optional[Dict] = None) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –ø–æ–º–æ—â—å—é YandexGPT"""
        if not self.available:
            logger.warning("‚ùå YandexGPT –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            return {
                "success": False,
                "message": "YandexGPT –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω",
                "type": "yandex_error"
            }
        
        try:
            logger.info(f"üß† YandexGPT: –ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞")
            logger.info(f"üß† YandexGPT: –ó–∞–ø—Ä–æ—Å: {query}")
            logger.info(f"üß† YandexGPT: User ID: {user_id}")
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞
            prompt = self._create_prompt(query, context)
            logger.info(f"üß† YandexGPT: –°–æ–∑–¥–∞–Ω –ø—Ä–æ–º–ø—Ç –¥–ª–∏–Ω–æ–π {len(prompt)} —Å–∏–º–≤–æ–ª–æ–≤")
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
            response = self._generate_text(prompt)
            logger.info(f"üß† YandexGPT: –û—Ç–≤–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –¥–ª–∏–Ω–æ–π {len(response)} —Å–∏–º–≤–æ–ª–æ–≤")
            
            return {
                "success": True,
                "message": response,
                "type": "yandex_response",
                "model": self.model_name,
                "device": self.device
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞ YandexGPT: {e}")
            return {
                "success": False,
                "message": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {str(e)}",
                "type": "yandex_error"
            }
    
    def _create_prompt(self, query: str, context: Optional[Dict] = None) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è YandexGPT"""
        
        prompt = f"""
–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–≤—Ç–æ–º–æ–±–∏–ª—è–º –ú–û–¢–û–†–ß–ò–ö. –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∑–∞–¥–∞–ª —Å–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å: "{query}"

"""
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç, –µ—Å–ª–∏ –µ—Å—Ç—å
        if context:
            if context.get('cars'):
                prompt += f"–î–æ—Å—Ç—É–ø–Ω—ã–µ –∞–≤—Ç–æ–º–æ–±–∏–ª–∏:\n"
                for i, car in enumerate(context['cars'][:5], 1):
                    prompt += f"{i}. {car.get('mark', 'N/A')} {car.get('model', 'N/A')}\n"
                    prompt += f"   –¶–µ–Ω–∞: {car.get('price', 'N/A')} ‚ÇΩ\n"
                    prompt += f"   –ì–æ–¥: {car.get('manufacture_year', 'N/A')}\n"
                    prompt += f"   –¶–≤–µ—Ç: {car.get('color', 'N/A')}\n"
                    prompt += f"   –ì–æ—Ä–æ–¥: {car.get('city', 'N/A')}\n\n"
        
        prompt += f"""
–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å –ø–æ–ª–µ–∑–Ω—ã–π –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. 
–ë—É–¥—å –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–º –∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–º. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, –ø—Ä–µ–¥–ª–æ–∂–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –ø–æ–∏—Å–∫–∞.
–û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.
"""
        
        return prompt
    
    def _generate_text(self, prompt: str) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é –º–æ–¥–µ–ª–∏"""
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ —á–∞—Ç–∞
        messages = [{"role": "user", "content": prompt}]
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —à–∞–±–ª–æ–Ω —á–∞—Ç–∞
        input_ids = self.tokenizer.apply_chat_template(
            messages, tokenize=True, return_tensors="pt"
        )
        
        if self.device == "cuda":
            input_ids = input_ids.to(self.device)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        with torch.no_grad():
            outputs = self.model.generate(
                input_ids, 
                max_new_tokens=512,
                temperature=0.7,
                do_sample=True,
                top_p=0.9,
                pad_token_id=self.tokenizer.eos_token_id
            )
        
        # –î–µ–∫–æ–¥–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        response = self.tokenizer.decode(outputs[0][input_ids.size(1):], skip_special_tokens=True)
        
        return response.strip()
    
    def is_available(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–∏—Å–∞"""
        return self.available
    
    def get_status(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ —Å–µ—Ä–≤–∏—Å–∞"""
        return {
            "available": self.available,
            "model_name": self.model_name,
            "device": self.device,
            "model_loaded": self.model is not None,
            "tokenizer_loaded": self.tokenizer is not None
        }

# –°–æ–∑–¥–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä —Å–µ—Ä–≤–∏—Å–∞
yandex_gpt_service = YandexGPTService()

def get_yandex_gpt_service() -> YandexGPTService:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ —Å–µ—Ä–≤–∏—Å–∞"""
    return yandex_gpt_service 